{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Obama, in full Barack Hussein Obama II, (born August 4, 1961, Honolulu, Hawaii, U.S.), 44th president of the United States (2009-17) and the first African American to hold the office. Before winning the presidency, Obama represented Illinois in the U.S. Senate (2005-08). He was the third African American to be elected to that body ... Barack Hussein Obama II (/ b ə ˈ r ɑː k h uː ˈ s eɪ n oʊ ˈ b ɑː m ə / bə-RAHK hoo-SAYN oh-BAH-mə; born August 4, 1961) is an American politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, he was the first African-American president. Obama previously served as a U.S. senator representing Illinois from 2005 to 2008 and ... Life After the Presidency How Tall is Obama? Books and Grammy Hobbies Movies About Obama Quotes 1961-present Who Is Barack Obama? Barack Obama was the 44 th president of the United States... Answer (1 of 12): I see others have answered President Obama\\'s name which is \"Barack Hussein Obama\". President Obama has received many comments about his name from the racists across US. It is worth noting that he never changed his name. Also, it is worth noting that a simple search would have re... As the head of the government of the United States, the president is arguably the most powerful government official in the world. The president is elected to a four-year term via an electoral college system. Since the Twenty-second Amendment was adopted in 1951, the American presidency has been'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.linkedin.com/pulse/ai-nlp-speech-recognition-machine-translation-next-chapter-wiggins],', 'https://omniscien.com/resources/webinars/],', 'https://www.reddit.com/r/machinetranslation/comments/ywrm8f/webinar_with_omniscien_ceo_dion_wiggins_and_chief/]']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "urls = re.findall(r'link:\\s(https?://\\S+)', result)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='لم يتم العثور على الصفحة\\n\\nعفواً، لم نتمكن من العثور على الصفحة التي تبحث عنها. برجاء المحاولة مرة أخرى للصفحة السابقة أو الانتقال لـمركز المساعدة للمزيد من المعلومات\\n\\nالإنتقال لموجزك الرئيسي\\n\\nStránka nenalezena\\n\\nOmlouváme se, nemůžeme najít stránku, kterou hledáte. Zkuste se vrátit zpátky na předchozí stránku, nebo se podívejte do našeho Centra nápovědy pro více informací\\n\\nPřejít do informačního kanálu\\n\\nSiden blev ikke fundet\\n\\nVi kan desværre ikke finde den side, du leder efter. Gå tilbage til den forrige side, eller besøg Hjælp for at få flere oplysninger\\n\\nGå til dit feed\\n\\nSeite nicht gefunden\\n\\nDie gewünschte Seite konnte leider nicht gefunden werden. Versuchen Sie, zur vorherigen Seite zurückzukehren, oder besuchen Sie unseren Hilfebereich, um mehr zu erfahren.\\n\\nZu Ihrem Feed\\n\\nPage not found\\n\\nUh oh, we can’t seem to find the page you’re looking for. Try going back to the previous page or see our Help Center for more information\\n\\nGo to your feed\\n\\nPágina no encontrada\\n\\nVaya, parece que no podemos encontrar la página que buscas. Intenta volver a la página anterior o visita nuestro Centro de ayuda para más información.\\n\\nIr a tu feed\\n\\nImpossible de trouver cette page\\n\\nNous ne trouvons pas la page que vous recherchez. Essayez de retourner à la page précédente ou consultez notre assistance clientèle pour plus d’informations\\n\\nOuvrez votre fil\\n\\nHalaman ini tidak dapat ditemukan\\n\\nMaaf, sepertinya kami tidak dapat menemukan halaman yang Anda cari. Coba kembali ke halaman sebelumnya atau lihat Pusat Bantuan kami untuk informasi lebih lanjut\\n\\nBuka feed Anda\\n\\nPagina non trovata\\n\\nNon abbiamo trovato la pagina che stai cercando. Prova a tornare alla pagina precedente o visita il nostro Centro assistenza per saperne di più.\\n\\nVai al tuo feed\\n\\nページが見つかりませんでした\\n\\n申し訳ありません。お探しのページが見つかりません。前のページに戻るか、ヘルプセンターで詳細をご確認ください\\n\\nフィードに移動\\n\\n페이지 없음\\n\\n원하시는 페이지를 찾을 수 없습니다. 이전 페이지로 돌아가거나 고객센터에서 자세히 알아보세요.\\n\\n홈으로 가기\\n\\nLaman tidak ditemui\\n\\nHarap maaf, kami tidak dapat menemui laman yang ingin anda cari. Cuba kembali ke laman sebelumnya atau lihat Pusat Bantuan kami untuk maklumat lanjut\\n\\nPergi ke suapan\\n\\nPagina niet gevonden\\n\\nDe pagina waar u naar op zoek bent, kan niet worden gevonden. Probeer terug te gaan naar de vorige pagina of bezoek het Help Center voor meer informatie\\n\\nGa naar uw feed\\n\\nFant ikke siden\\n\\nVi finner ikke siden du leter etter. Gå tilbake til forrige side eller besøk vår brukerstøtte for mer informasjon\\n\\nGå til din feed\\n\\nNie znaleziono strony\\n\\nNie możemy znaleźć strony, której szukasz. Spróbuj wrócić do poprzedniej strony lub nasze Centrum pomocy, aby uzyskać więcej informacji\\n\\nPrzejdź do swojego kanału\\n\\nPágina não encontrada\\n\\nA página que você está procurando não foi encontrada. Volte para a página anterior ou visite nossa Central de Ajuda para mais informações\\n\\nVoltar para seu feed\\n\\nPagina nu a fost găsită\\n\\nNe pare rău, nu găsim pagina pe care o căutaţi. Reveniţi la pagina anterioară sau consultaţi Centrul nostru de asistenţă pentru mai multe informaţii\\n\\nAccesaţi fluxul dvs.\\n\\nСтраница не найдена\\n\\nНе удаётся найти искомую вами страницу. Вернитесь на предыдущую страницу или посетите страницу нашего справочного центра для получения дополнительной информации.\\n\\nПерейти к ленте\\n\\nSidan kunde inte hittas.\\n\\nSidan du letar efter hittades inte. Gå tillbaka till föregående sida eller besök vårt Hjälpcenter för mer information\\n\\nGå till ditt nyhetsflöde\\n\\nไม่พบหน้าเพจ\\n\\nขออภัย ดูเหมือนเราไม่พบหน้าที่คุณกำลังมองหาอยู่ ลองกลับไปที่หน้าเพจก่อน หรือดู ศูนย์ความช่วยเหลือ ของเราสำหรับข้อมูลเพิ่มเติม\\n\\nไปที่ฟีดของคุณ\\n\\nHindi Nahanap ang Pahina\\n\\nNaku, mukhang hindi namin mahanap ang pahina na hinahanap mo. Subukang bumalik sa nakaraang pahina o tingnan ang aming Help Center para sa higit pang impormasyon\\n\\nPumunta sa iyong feed\\n\\nSayfa bulunamadı\\n\\nAradığınız sayfa bulunamadı. Önceki sayfaya geri dönün veya daha fazla bilgi için Yardım Merkezimizi görüntüleyin\\n\\nHaber akışınıza gidin\\n\\n未找到网页\\n\\n抱歉，无法找到页面。试试返回到前一页，或前往帮助中心了解更多信息\\n\\n前往动态汇总\\n\\n系統找不到頁面。\\n\\n我們好像找不到該頁面。請回到上一頁或前往說明中心來進一步瞭解\\n\\n前往首頁動態\\n\\n© 2022\\n\\nاتفاقية المستخدم\\n\\nسياسة الخصوصية\\n\\nإرشادات المجتمع\\n\\nسياسة ملفات تعريف الارتباط\\n\\nسياسة حقوق النشر\\n\\nإعدادات إدارة الضيوف\\n\\nSmlouva s uživatelem\\n\\nZásady ochrany soukromí\\n\\nZásady komunity\\n\\nZásady pro soubory cookie\\n\\nZásady ochrany autorských práv\\n\\nVolby pro hosty\\n\\nBrugeraftale\\n\\nPrivatlivspolitik\\n\\nForumretningslinjer\\n\\nPolitik for cookies\\n\\nOphavsretspolitik\\n\\nIndstillinger for gæster\\n\\nNutzervereinbarung\\n\\nDatenschutzrichtlinie\\n\\nNetzwerkrichtlinien\\n\\nCookie-Richtlinie\\n\\nCopyright-Richtlinie\\n\\nEinstellungen für Nichtmitglieder\\n\\nUser Agreement\\n\\nPrivacy Policy\\n\\nCommunity Guidelines\\n\\nCookie Policy\\n\\nCopyright Policy\\n\\nGuest Controls\\n\\nCondiciones de uso\\n\\nPolítica de privacidad\\n\\nDirectrices comunitarias\\n\\nPolítica de cookies\\n\\nPolítica de copyright\\n\\nControles de invitados\\n\\nConditions générales d’utilisation de LinkedIn\\n\\nPolitique de confidentialité\\n\\nDirectives de la communauté\\n\\nPolitique relative aux cookies\\n\\nPolitique de copyright\\n\\nRéglages invités\\n\\nPerjanjian Pengguna\\n\\nKebijakan Privasi\\n\\nPanduan Komunitas\\n\\nKebijakan Cookie\\n\\nKebijakan Hak Cipta\\n\\nPengaturan Tamu\\n\\nContratto di licenza\\n\\nInformativa sulla privacy\\n\\nLinee guida della community\\n\\nInformativa sui cookie\\n\\nInformativa sul copyright\\n\\nControlli ospite\\n\\n利用規約\\n\\nプライバシーポリシー\\n\\nコミュニティガイドライン\\n\\nCookieポリシー\\n\\n著作権ポリシー\\n\\nゲスト向け管理機能\\n\\n사용자약관\\n\\n개인정보 취급방침\\n\\n커뮤니티정책\\n\\n쿠키정책\\n\\n저작권정책\\n\\n비회원 설정\\n\\nPerjanjian Pengguna\\n\\nDasar Privasi\\n\\nGaris Panduan Komuniti\\n\\nDasar Kuki\\n\\nDasar Hak Cipta\\n\\nKawalan Tetamu\\n\\nGebruikersovereenkomst\\n\\nPrivacybeleid\\n\\nCommunityrichtlijnen\\n\\nCookiebeleid\\n\\nAuteursrechtenbeleid\\n\\nInstellingen voor gasten\\n\\nBrukeravtale\\n\\nPersonvernerklæring\\n\\nRetningslinjer for fellesskapet\\n\\nRetningslinjer for informasjonskapsler\\n\\nRetningslinjer vedrørende opphavsrett\\n\\nGjestestyring\\n\\nUmowa użytkownika\\n\\nPolityka ochrony prywatności\\n\\nWskazówki dotyczące społeczności\\n\\nZasady korzystania z plików cookie\\n\\nCopyright\\n\\nUstawienia gościa\\n\\nContrato do Usuário\\n\\nPolítica de Privacidade do LinkedIn\\n\\nDiretrizes da Comunidade\\n\\nPolítica de Cookies\\n\\nPolítica de Direitos Autorais\\n\\nControles de visitantes\\n\\nAcordul utilizatorului\\n\\nPolitica de confidențialitate\\n\\nLinii directoare comunitate\\n\\nPolitica privind modulele cookie\\n\\nPolitica de copyright\\n\\nControale vizitator\\n\\nПользовательское соглашение\\n\\nПолитика конфиденциальности\\n\\nПравила сообщества\\n\\nПолитика использования файлов cookie\\n\\nПолитика защиты авторских прав\\n\\nНастройки гостя\\n\\nAnvändaravtal\\n\\nSekretesspolicy\\n\\nRiktlinjer\\n\\nCookiepolicy\\n\\nUpphovsrättspolicy\\n\\nGästinställningar\\n\\nข้อตกลงผู้ใช้\\n\\nนโยบายสิทธิส่วนบุคคล\\n\\nแนวทางชุมชน\\n\\nนโยบายสำหรับคุกกี้\\n\\nนโยบายลิขสิทธิ์\\n\\nการควบคุมสำหรับผู้เยี่ยมชม\\n\\nKasunduan sa Gumagamit\\n\\nPatakaran sa Pagkapribado\\n\\nMga alituntunin sa komunidad\\n\\nPatakara sa Cookie\\n\\nPatakaran sa Copyright\\n\\nMga kontrol ng Panauhin\\n\\nKullanıcı Anlaşması\\n\\nGizlilik Politikası\\n\\nTopluluk Yönergeleri\\n\\nÇerez Politikası\\n\\nTelif Hakkı Politikası\\n\\nZiyaretçi Kontrolleri\\n\\n用户协议\\n\\n隐私政策\\n\\n社区准则\\n\\nCookie 政策\\n\\n版权政策\\n\\n访客设置\\n\\n用戶協議\\n\\n隱私權政策\\n\\n社群指南\\n\\nCookie 政策\\n\\n著作權政策\\n\\n訪客控管', metadata={'source': 'https://www.linkedin.com/pulse/ai-nlp-speech-recognition-machine-translation-next-chapter-wiggins],'}),\n",
       " Document(page_content='403 - Forbidden | Access to this page is forbidden.', metadata={'source': 'https://omniscien.com/resources/webinars/],'}),\n",
       " Document(page_content='Advertisement\\n\\nCoins\\n            0 coins\\n\\nPremium\\n\\nPowerups\\n\\nPopular Posts\\n\\nHelp Center\\n\\nReddit iOS\\n\\nReddit Android\\n\\nReddit Premium\\n\\nAbout Reddit\\n\\nAdvertise\\n\\nBlog\\n\\nCareers\\n\\nPress\\n\\nUser Agreement\\n\\nPrivacy Policy\\n\\nContent Policy\\n\\nModerator Guidelines\\n\\nSign Up or Log In\\n\\nOops, something went wrong, please try again later.', metadata={'source': 'https://www.reddit.com/r/machinetranslation/comments/ywrm8f/webinar_with_omniscien_ceo_dion_wiggins_and_chief/]'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.utilities import PythonREPL\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "import wikipedia\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func= search.run,\n",
    "    description=\"Useful for when you need to do a search on the internet to find information that another tool can't find. be specific with your input.\"\n",
    ")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/sira/sira_project/meta-Llama2/llama-2-7b-chat.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 7354.73 MB (+ 2048.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 2048.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=load_llm(),\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      " Let me see if I can find any information about him online.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins\"\n",
      "Action Input: \"Dion Wiggins\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 52344.68 ms\n",
      "llama_print_timings:      sample time =    27.68 ms /    47 runs   (    0.59 ms per token,  1698.16 tokens per second)\n",
      "llama_print_timings: prompt eval time = 52344.54 ms /   187 tokens (  279.92 ms per token,     3.57 tokens per second)\n",
      "llama_print_timings:        eval time = 14647.88 ms /    46 runs   (  318.43 ms per token,     3.14 tokens per second)\n",
      "llama_print_timings:       total time = 67187.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m Let me see if I can find any information about him online.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins\"\n",
      "Action Input: \"Dion Wiggins\"\u001b[0m\n",
      "Observation: [DuckDuckGo Search] \"Dion Wiggins\" is not a valid tool, try another one.\n",
      "Thought: Hmm, that didn't work. Let me try again.\n",
      "Question: What is Dion Wiggins' occupation?\n",
      "Thought: I wonder if he has a website or social media profile where I can find more information about him.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins website\"\n",
      "Action Input: \"Dion Wiggins website\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 52344.68 ms\n",
      "llama_print_timings:      sample time =    50.20 ms /    86 runs   (    0.58 ms per token,  1713.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  8844.19 ms /    30 tokens (  294.81 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:        eval time = 27604.14 ms /    85 runs   (  324.75 ms per token,     3.08 tokens per second)\n",
      "llama_print_timings:       total time = 36798.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m Hmm, that didn't work. Let me try again.\n",
      "Question: What is Dion Wiggins' occupation?\n",
      "Thought: I wonder if he has a website or social media profile where I can find more information about him.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins website\"\n",
      "Action Input: \"Dion Wiggins website\"\u001b[0m\n",
      "Observation: [DuckDuckGo Search] \"Dion Wiggins website\" is not a valid tool, try another one.\n",
      "Thought: Okay, let me try searching for his social media profiles instead.\n",
      "Question: What are Dion Wiggins' social media profiles?\n",
      "Thought: I hope he has LinkedIn profile so I can see his professional background and connections.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins LinkedIn\"\n",
      "Action Input: \"Dion Wiggins LinkedIn\"\u001b[32;1m\u001b[1;3m Okay, let me try searching for his social media profiles instead.\n",
      "Question: What are Dion Wiggins' social media profiles?\n",
      "Thought: I hope he has LinkedIn profile so I can see his professional background and connections.\n",
      "Action: [DuckDuckGo Search] \"Dion Wiggins LinkedIn\"\n",
      "Action Input: \"Dion Wiggins LinkedIn\"\u001b[0m\n",
      "Observation: [DuckDuckGo Search] \"Dion Wiggins LinkedIn\" is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 52344.68 ms\n",
      "llama_print_timings:      sample time =    48.59 ms /    87 runs   (    0.56 ms per token,  1790.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  8718.20 ms /    31 tokens (  281.23 ms per token,     3.56 tokens per second)\n",
      "llama_print_timings:        eval time = 27108.81 ms /    86 runs   (  315.22 ms per token,     3.17 tokens per second)\n",
      "llama_print_timings:       total time = 36181.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent.run(\"Who is Dion Wiggins?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Optional\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.tools.base import BaseTool\n",
    "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "class DuckDuckGoSearchResults(BaseTool):\n",
    "    \"\"\"Tool that queries the DuckDuckGo search API and gets back json.\"\"\"\n",
    "\n",
    "    name = \"DuckDuckGo Results JSON\"\n",
    "    description = (\n",
    "        \"A wrapper around Duck Duck Go Search. \"\n",
    "        \"Useful for when you need to answer questions about current events. \"\n",
    "        \"Input should be a search query. Output is a JSON array of the query results\"\n",
    "    )\n",
    "    num_results: int = 10\n",
    "    api_wrapper: DuckDuckGoSearchAPIWrapper = Field(\n",
    "        default_factory=DuckDuckGoSearchAPIWrapper\n",
    "    )\n",
    "    backend: str = \"api\"\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        res = self.api_wrapper.results(query, self.num_results, backend=self.backend)\n",
    "        return res\n",
    "        # res_strs = [\", \".join([f\"{k}: {v}\" for k, v in d.items()]) for d in res]\n",
    "        # return [f\"[{rs}]\" for rs in res_strs], res_strs, res\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"DuckDuckGoSearchResults does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"th-th\", time=\"w\", max_results=10)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, num_results = 10)\n",
    "res = search.run(\"What is Omniscien Technology?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'snippet': 'omniscient: [adjective] having infinite awareness, understanding, and insight.',\n",
       "  'title': 'Omniscient Definition & Meaning - Merriam-Webster',\n",
       "  'link': 'https://www.merriam-webster.com/dictionary/omniscient'},\n",
       " {'snippet': '1. You are never going to surprise God. He is omniscient. Lord, you have searched me and known me. You know when I sit down and when I stand up; you understand my thoughts from far away. You observe my travels and my rest; you are aware of all my ways. Before a word is on my tongue, you know all about it, Lord.',\n",
       "  'title': 'A Big Question Technology Raises and Theology Answers',\n",
       "  'link': 'https://ericgeiger.com/2023/08/a-big-question-technology-raises-and-theology-answers/'},\n",
       " {'snippet': 'Omniscient definition, having complete or unlimited knowledge, awareness, or understanding; perceiving all things. See more.',\n",
       "  'title': 'Omniscient Definition & Meaning | Dictionary.com',\n",
       "  'link': 'https://www.dictionary.com/browse/omniscient'},\n",
       " {'snippet': 'These limitations should serve as a reminder that this technology is a tool, not an omniscient entity. AI is only as good as the data it receives and the assumptions made. Garbage in, garbage out, as they say. It is essential to approach implementation of AI with a critical mindset and to understand the inherent biases and limitations that can ...',\n",
       "  'title': \"Why I don't fear the AI revolution - Aerospace America\",\n",
       "  'link': 'https://aerospaceamerica.aiaa.org/departments/why-i-dont-fear-the-ai-revolution/'},\n",
       " {'snippet': \"Katherine Polk Failla, the judge who made the ruling, is the same judge overseeing the U.S. Securities and Exchange Commission's (SEC) lawsuit against Coinbase that it launched on allegations that the crypto exchange was selling unregistered securities. Last month, Failla voiced her concerns over the fact that the SEC didn't warn Coinbase ...\",\n",
       "  'title': \"Judge Overseeing SEC's Coinbase Lawsuit Dismisses Class Action Against ...\",\n",
       "  'link': 'https://dailyhodl.com/2023/08/30/judge-overseeing-secs-coinbase-lawsuit-dismisses-class-action-against-uniswap/'},\n",
       " {'snippet': 'Define omniscient. omniscient synonyms, omniscient pronunciation, omniscient translation, English dictionary definition of omniscient. adj. Having total knowledge; knowing everything: an omniscient deity; the omniscient narrator.',\n",
       "  'title': 'Omniscient - definition of omniscient by The Free Dictionary',\n",
       "  'link': 'https://www.thefreedictionary.com/omniscient'},\n",
       " {'snippet': 'Omniscience is a related term of omniscient. As an adjective omniscient is having total knowledge. As a proper noun Omniscient is god. As a noun omniscience is the capacity to know everything.',\n",
       "  'title': \"Omniscient vs Omniscience - What's the difference? | WikiDiff\",\n",
       "  'link': 'https://wikidiff.com/omniscient/omniscience'},\n",
       " {'snippet': 'The term \"information technology\" was coined in 1958, when authors Harold J. Leavitt and Thomas L. Whisler commented on an article published in the Harvard Business Review stating that a new technology had emerged that did not have an established name.',\n",
       "  'title': 'What is Information Technology | DeVry University',\n",
       "  'link': 'https://www.devry.edu/online-programs/area-of-study/technology/what-is-information-technology.html'},\n",
       " {'snippet': 'omniscient: 1 adj infinitely wise Synonyms: all-knowing wise having or prompted by wisdom or discernment',\n",
       "  'title': 'Omniscient - Definition, Meaning & Synonyms | Vocabulary.com',\n",
       "  'link': 'https://www.vocabulary.com/dictionary/omniscient'},\n",
       " {'snippet': 'Mobile information technology, also known as mobile IT, refers to the use of mobile technology, devices, and applications for accessing, processing, and sharing information remotely. It encompasses a broad range of technologies, including smartphones, tablets, laptops, wearable technology, and other wireless devices.',\n",
       "  'title': 'What is mobile IT (mobile information technology)?',\n",
       "  'link': 'https://www.thetechedvocate.org/what-is-mobile-it-mobile-information-technology/'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dion Wiggins Chief Technology Officer at Omniscien Technologies Published Jan 12, 2023 + Follow During my time and Vice President and Research Director at Gartner, many approaches were used...'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][\"snippet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseRetriever, Document\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Optional\n",
    "from langchain.llms.base import BaseLLM\n",
    "from langchain.prompts import BasePromptTemplate, PromptTemplate\n",
    "from langchain.chains.prompt_selector import ConditionalPromptSelector\n",
    "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForRetrieverRun,\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "\n",
    "class LineList(BaseModel):\n",
    "    \"\"\"List of questions.\"\"\"\n",
    "\n",
    "    lines: List[str] = Field(description=\"Questions\")\n",
    "\n",
    "class QuestionListOutputParser(PydanticOutputParser):\n",
    "    \"\"\"Output parser for a list of numbered questions.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = re.findall(r\"\\d+\\..*?\\n\", text)\n",
    "        return LineList(lines=lines)\n",
    "\n",
    "class WebResearchRetriever(BaseRetriever):\n",
    "    # Inputs\n",
    "    vectorstore: VectorStore = Field(\n",
    "        ..., description=\"Vector store for storing web pages\"\n",
    "    )\n",
    "    llm_chain: LLMChain\n",
    "    search: DuckDuckGoSearchAPIWrapper = Field(..., description=\"DuckDuckGo API Wrapper\")\n",
    "    num_search_results: int = Field(1, description=\"Number of pages per DuckDuckGo \")\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(\n",
    "        RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50),\n",
    "        description=\"Text splitter for splitting web pages into chunks\",\n",
    "    )\n",
    "    url_database: List[str] = Field(\n",
    "        default_factory=list, description=\"List of processed URLs\"\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls,\n",
    "        vectorstore: VectorStore,\n",
    "        llm: BaseLLM,\n",
    "        search: DuckDuckGoSearchAPIWrapper,\n",
    "        prompt: Optional[BasePromptTemplate] = None,\n",
    "        num_search_results: int = 1,\n",
    "        text_splitter: RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1500, chunk_overlap=150\n",
    "        ),\n",
    "    ) -> \"WebResearchRetriever\":\n",
    "        \"\"\"Initialize from llm using default template.\n",
    "\n",
    "        Args:\n",
    "            vectorstore: Vector store for storing web pages\n",
    "            llm: llm for search question generation\n",
    "            search: GoogleSearchAPIWrapper\n",
    "            prompt: prompt to generating search questions\n",
    "            num_search_results: Number of pages per Google search\n",
    "            text_splitter: Text splitter for splitting web pages into chunks\n",
    "\n",
    "        Returns:\n",
    "            WebResearchRetriever\n",
    "        \"\"\"\n",
    "        DEFAULT_LLAMA_SEARCH_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"<<SYS>> \\n You are an assistant tasked with improving Google search \n",
    "        results. \\n <</SYS>> \\n\\n [INST] Generate THREE Google search queries that \n",
    "        are similar to this question. The output should be a numbered list of questions \n",
    "        and each should have a question mark at the end: \\n\\n {question} [/INST]\"\"\",)\n",
    "\n",
    "\n",
    "        DEFAULT_SEARCH_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"You are an assistant tasked with improving Google search \n",
    "        results. Generate THREE Google search queries that are similar to\n",
    "        this question. The output should be a numbered list of questions and each\n",
    "        should have a question mark at the end: {question}\"\"\",)\n",
    "\n",
    "        if not prompt:\n",
    "            QUESTION_PROMPT_SELECTOR = ConditionalPromptSelector(\n",
    "                default_prompt=DEFAULT_SEARCH_PROMPT,\n",
    "                conditionals=[\n",
    "                    (lambda llm: isinstance(llm, LlamaCpp), DEFAULT_LLAMA_SEARCH_PROMPT)\n",
    "                ],\n",
    "            )\n",
    "            prompt = QUESTION_PROMPT_SELECTOR.get_prompt(llm)\n",
    "\n",
    "        # Use chat model prompt\n",
    "        llm_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=prompt,\n",
    "            output_parser=QuestionListOutputParser(),\n",
    "        )\n",
    "\n",
    "        return cls(\n",
    "            vectorstore=vectorstore,\n",
    "            llm_chain=llm_chain,\n",
    "            search=search,\n",
    "            num_search_results=num_search_results,\n",
    "            text_splitter=text_splitter,\n",
    "        ) #output\n",
    "    \n",
    "    def clean_search_query(self, query: str) -> str:\n",
    "        # Some search tools (e.g., Google) will\n",
    "        # fail to return results if query has a\n",
    "        # leading digit: 1. \"LangCh...\"\n",
    "        # Check if the first character is a digit\n",
    "        if query[0].isdigit():\n",
    "            # Find the position of the first quote\n",
    "            first_quote_pos = query.find('\"')\n",
    "            if first_quote_pos != -1:\n",
    "                # Extract the part of the string after the quote\n",
    "                query = query[first_quote_pos + 1 :]\n",
    "                # Remove the trailing quote if present\n",
    "                if query.endswith('\"'):\n",
    "                    query = query[:-1]\n",
    "        return query.strip()\n",
    "\n",
    "    def search_tool(self, query: str, num_search_results: int = 1) -> List[dict]:\n",
    "        \"\"\"Returns num_serch_results pages per Google search.\"\"\"\n",
    "        query_clean = self.clean_search_query(query)\n",
    "        result = self.search.results(query_clean, num_search_results)\n",
    "        return result\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: CallbackManagerForRetrieverRun,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Search DuckDuckgo for documents related to the query input.\n",
    "\n",
    "        Args:\n",
    "            query: user query\n",
    "\n",
    "        Returns:\n",
    "            Relevant documents from all various urls.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get search questions\n",
    "        logger.info(\"Generating questions for DuckDuckgo Search ...\")\n",
    "        result = self.llm_chain({\"question\": query})\n",
    "        logger.info(f\"Questions for DuckDuckgo Search (raw): {result}\")\n",
    "        questions = getattr(result[\"text\"], \"lines\", [])\n",
    "        logger.info(f\"Questions for DuckDuckgo Search: {questions}\")\n",
    "\n",
    "        # Get urls\n",
    "        logger.info(\"Searching for relevat urls ...\")\n",
    "        urls_to_look = []\n",
    "        for query in questions:\n",
    "            # Google search\n",
    "            search_results = self.search_tool(query, self.num_search_results)\n",
    "            logger.info(\"Searching for relevat urls ...\")\n",
    "            logger.info(f\"Search results: {search_results}\")\n",
    "            for res in search_results:\n",
    "                urls_to_look.append(res[\"link\"])\n",
    "\n",
    "        # Relevant urls\n",
    "        urls = set(urls_to_look)\n",
    "\n",
    "        # Check for any new urls that we have not processed\n",
    "        new_urls = list(urls.difference(self.url_database))\n",
    "\n",
    "        logger.info(f\"New URLs to load: {new_urls}\")\n",
    "        # Load, split, and add new urls to vectorstore\n",
    "        if new_urls:\n",
    "            loader = AsyncHtmlLoader(new_urls)\n",
    "            html2text = Html2TextTransformer()\n",
    "            logger.info(\"Indexing new urls...\")\n",
    "            docs = loader.load()\n",
    "            docs = list(html2text.transform_documents(docs))\n",
    "            docs = self.text_splitter.split_documents(docs)\n",
    "            self.vectorstore.add_documents(docs)\n",
    "            self.url_database.extend(new_urls)\n",
    "\n",
    "        # Search for relevant splits\n",
    "        # TODO: make this async\n",
    "        logger.info(\"Grabbing most relevant splits from urls...\")\n",
    "        docs = []\n",
    "        for query in questions:\n",
    "            docs.extend(self.vectorstore.similarity_search(query))\n",
    "\n",
    "        # Get unique docs\n",
    "        unique_documents_dict = {\n",
    "            (doc.page_content, tuple(sorted(doc.metadata.items()))): doc for doc in docs\n",
    "        }\n",
    "        unique_documents = list(unique_documents_dict.values())\n",
    "        return unique_documents\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        run_manager: AsyncCallbackManagerForRetrieverRun,\n",
    "    ) -> List[Document]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/sira/sira_project/meta-Llama2/llama-2-7b-chat.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 7354.73 MB (+ 2048.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 2048.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "13 validation errors for WebResearchRetriever\nsearch -> api_wrapper\n  extra fields not permitted (type=value_error.extra)\nsearch -> args_schema\n  extra fields not permitted (type=value_error.extra)\nsearch -> backend\n  extra fields not permitted (type=value_error.extra)\nsearch -> callback_manager\n  extra fields not permitted (type=value_error.extra)\nsearch -> callbacks\n  extra fields not permitted (type=value_error.extra)\nsearch -> description\n  extra fields not permitted (type=value_error.extra)\nsearch -> handle_tool_error\n  extra fields not permitted (type=value_error.extra)\nsearch -> metadata\n  extra fields not permitted (type=value_error.extra)\nsearch -> name\n  extra fields not permitted (type=value_error.extra)\nsearch -> num_results\n  extra fields not permitted (type=value_error.extra)\nsearch -> return_direct\n  extra fields not permitted (type=value_error.extra)\nsearch -> tags\n  extra fields not permitted (type=value_error.extra)\nsearch -> verbose\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Initialize\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m web_research_retriever \u001b[39m=\u001b[39m WebResearchRetriever\u001b[39m.\u001b[39;49mfrom_llm(\n\u001b[1;32m      3\u001b[0m     vectorstore\u001b[39m=\u001b[39;49mvectorstore,\n\u001b[1;32m      4\u001b[0m     llm\u001b[39m=\u001b[39;49mload_llm(), \n\u001b[1;32m      5\u001b[0m     search\u001b[39m=\u001b[39;49msearch, \n\u001b[1;32m      6\u001b[0m )\n",
      "Cell \u001b[0;32mIn[173], line 103\u001b[0m, in \u001b[0;36mWebResearchRetriever.from_llm\u001b[0;34m(cls, vectorstore, llm, search, prompt, num_search_results, text_splitter)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m# Use chat model prompt\u001b[39;00m\n\u001b[1;32m     97\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(\n\u001b[1;32m     98\u001b[0m     llm\u001b[39m=\u001b[39mllm,\n\u001b[1;32m     99\u001b[0m     prompt\u001b[39m=\u001b[39mprompt,\n\u001b[1;32m    100\u001b[0m     output_parser\u001b[39m=\u001b[39mQuestionListOutputParser(),\n\u001b[1;32m    101\u001b[0m )\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    104\u001b[0m     vectorstore\u001b[39m=\u001b[39;49mvectorstore,\n\u001b[1;32m    105\u001b[0m     llm_chain\u001b[39m=\u001b[39;49mllm_chain,\n\u001b[1;32m    106\u001b[0m     search\u001b[39m=\u001b[39;49msearch,\n\u001b[1;32m    107\u001b[0m     num_search_results\u001b[39m=\u001b[39;49mnum_search_results,\n\u001b[1;32m    108\u001b[0m     text_splitter\u001b[39m=\u001b[39;49mtext_splitter,\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/lang-lama/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/lang-lama/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 13 validation errors for WebResearchRetriever\nsearch -> api_wrapper\n  extra fields not permitted (type=value_error.extra)\nsearch -> args_schema\n  extra fields not permitted (type=value_error.extra)\nsearch -> backend\n  extra fields not permitted (type=value_error.extra)\nsearch -> callback_manager\n  extra fields not permitted (type=value_error.extra)\nsearch -> callbacks\n  extra fields not permitted (type=value_error.extra)\nsearch -> description\n  extra fields not permitted (type=value_error.extra)\nsearch -> handle_tool_error\n  extra fields not permitted (type=value_error.extra)\nsearch -> metadata\n  extra fields not permitted (type=value_error.extra)\nsearch -> name\n  extra fields not permitted (type=value_error.extra)\nsearch -> num_results\n  extra fields not permitted (type=value_error.extra)\nsearch -> return_direct\n  extra fields not permitted (type=value_error.extra)\nsearch -> tags\n  extra fields not permitted (type=value_error.extra)\nsearch -> verbose\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever.from_llm(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=load_llm(), \n",
    "    search=search, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector from DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DuckDuckGoSearchResults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m DuckDuckGoSearchAPIWrapper\n\u001b[1;32m      2\u001b[0m wrapper \u001b[39m=\u001b[39m DuckDuckGoSearchAPIWrapper(region\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mth-th\u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, max_results\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m search \u001b[39m=\u001b[39m DuckDuckGoSearchResults(num_results \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m res \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39mrun(\u001b[39m\"\u001b[39m\u001b[39mWho is Dion Wiggins\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DuckDuckGoSearchResults' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"th-th\", time=\"w\", max_results=10)\n",
    "search = DuckDuckGoSearchResults(num_results = 10)\n",
    "res = search.run(\"Who is Dion Wiggins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'snippet': \"Sarah Morgan. Barrett. Sam Coe. Andreja. Matteo. Noel. Vlad. Walter Shroud. Starfield is Bethesda's first brand-new series (or IP, in technical speak) in almost 25 years, so it's safe to say there ...\",\n",
       "  'title': 'Starfield voice actors and cast list so far | TechRadar',\n",
       "  'link': 'https://www.techradar.com/gaming/starfield-voice-actors-list'},\n",
       " {'snippet': '1 / 6 Dion Wiggins \"You can\\'t lie to D.C. residents in order to protect your image, your profits and get away with it, no matter who you are,\" Racine said, before detailing the next steps in...',\n",
       "  'title': 'Commanders, NFL, Dan Snyder sued by DC for deceiving fans | wusa9.com',\n",
       "  'link': 'https://www.wusa9.com/article/sports/nfl/washington-commanders/washington-dc-attorney-general-sues-commanders-dan-snyder-over-sexual-harassment-nfl-for-phony-independent-investigation-that-followed/65-a3653489-5696-4ffb-9fa8-6bf1300b01c5'},\n",
       " {'snippet': \"WUSA-TV. Mar 2010 - Present13 years 6 months. Operate microwave / satellite truck for live events, and video tape special events, breaking news, and sports for newscast. provide sot's and vo's for ...\",\n",
       "  'title': 'Dion Wiggins - Photojournalist - WUSA-TV | LinkedIn',\n",
       "  'link': 'https://www.linkedin.com/in/dion-wiggins-a07b0915'},\n",
       " {'snippet': \"Join Omniscien's Philip Koehn and Dion Wiggins for a comprehensive review of the rapidly evolving AI landscape from the context of enterprise enablement via AI, best practices, risk management,...\",\n",
       "  'title': 'The Future of Language Related AI for Enterprises: Local ... - LinkedIn',\n",
       "  'link': 'https://www.linkedin.com/pulse/future-language-related-ai-enterprises-local-agents-large-wiggins'},\n",
       " {'snippet': \"A well-known pioneer of the Asian Internet Industry, a respected innovator and founder of Asia Online, one of the first Asian Internet Services Providers. I was also founder of The ActiveX Factory, where I was recipient of the Chairman's Commendation Award presented by Microsoft's Bill Gates for the best showcase of software developed in the Philippines and I have been recognized by the U.S ...\",\n",
       "  'title': 'Dion Wiggins | LinkedIn',\n",
       "  'link': 'https://sg.linkedin.com/in/dionwiggins'},\n",
       " {'snippet': 'Alan M. Nov, 2021 Safety is so important. Knowing who my family is associating with is paramount. Thank you, Instant Checkmate. dion antwan wiggins 3510 Round Hill Ln, District Heights, Md 20747-3871 56 year old Who is Dion Antwan Wiggins? Dion Antwan Wiggins is 56 years old and lives in District Heights, Maryland. Dion was born in December 1966.',\n",
       "  'title': 'Dion Wiggins Found! - See Phones, Email, Addresses, and More',\n",
       "  'link': 'https://www.instantcheckmate.com/people/dion-wiggins/'},\n",
       " {'snippet': 'View the profiles of people named Dion Wiggins. Join Facebook to connect with Dion Wiggins and others you may know. Facebook gives people the power to...',\n",
       "  'title': 'Dion Wiggins Profiles | Facebook',\n",
       "  'link': 'https://www.facebook.com/public/Dion-Wiggins'},\n",
       " {'snippet': 'Associated Social Media https://twitter.com/dwigginsdion https://linkedin.com/in/dion-wiggins-a07b0915 Show more (+) Associated Phone Numbers (301) 627-5898 (301) 808-1575 (202) 779-3213 (202) 258-8675 (301) 350-9874 (301) 938-3801',\n",
       "  'title': 'Found: Dion Wiggins in Maryland Public Records - Instant Checkmate',\n",
       "  'link': 'https://www.instantcheckmate.com/people/dion-wiggins/maryland/'},\n",
       " {'snippet': \"Bio Videos Stats / dion wiggins Deon Wiggins III Latest Updates Deon Wiggins III's highlights West Boca Raton High School 4 views | More Videos: dion wiggins dion wiggins's Bio Full Bio Added to Roster Friday, Jun 2, 2023 Deon has been added to the Blanche Ely 2023 football roster. Deon's Roster Schedule Video Friday, Jan 20, 2023\",\n",
       "  'title': \"Deon Wiggins III's (Pompano Beach, FL) Blanche Ely High ... - MaxPreps\",\n",
       "  'link': 'https://www.maxpreps.com/fl/pompano-beach/blanche-ely-tigers/athletes/deon-wiggins-iii/?careerid=oda5eks96j900'},\n",
       " {'snippet': 'Resides in Colorado Springs, CO. Lived In West Linn OR, Lake Oswego OR, Santa Clarita CA, Duluth MN. Related To Galen Doucette, Damian Doucette, Melissa Doucette, Donald Doucette. Also known as Janis Dawn Wiggins, Dawn Doubette, Dion P Wiggins, Dawn J Wiggins, Dawn S Doucette, J Dawn Wiggins. Includes Address (13) Phone (8) Email (7) See ...',\n",
       "  'title': 'Dion Wiggins (23 matches): Phone Number, Email, Address - Spokeo',\n",
       "  'link': 'https://www.spokeo.com/Dion-Wiggins'}]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "def text_to_document(web_data):\n",
    "    docs = []\n",
    "    for data in web_data:\n",
    "        text = data[\"snippet\"]\n",
    "        metadata = {\"title\" : data[\"title\"], \"source\" : data[\"link\"]}\n",
    "        subdoc = Document(page_content = text, metadata = metadata)\n",
    "        docs.append(Document(page_content = text, metadata = metadata))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = text_to_document(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='t. e. Omniscience ( / ɒmˈnɪʃəns /) [1] is the capacity to know everything. In Buddhism, Hinduism, Sikhism and the Abrahamic religions, this is an attribute of God. In Jainism, omniscience is an attribute that any individual can eventually attain. In Buddhism, there are differing beliefs about omniscience among different schools.', metadata={'title': 'Omniscience - Wikipedia', 'source': 'https://en.wikipedia.org/wiki/Omniscience'}),\n",
       " Document(page_content='omniscient: [adjective] having infinite awareness, understanding, and insight.', metadata={'title': 'Omniscient Definition & Meaning - Merriam-Webster', 'source': 'https://www.merriam-webster.com/dictionary/omniscient'}),\n",
       " Document(page_content='Omniscien Technologies Rise of the Machines: Balancing Language-Related AI Opportunities and Risks Securing the Future of Generative AI, Machine Translation, Speech Recognition, NLP and AI Augmented Processes Tuesday 25 April 2023 Watch the Replay', metadata={'title': 'Webinars - Omniscien Technologies', 'source': 'https://omniscien.com/resources/webinars/'}),\n",
       " Document(page_content='The Omniscient Technology enables creating \"the first ultraintelligent machine, the last invention that man need ever make\", as True Real AI or Causal Machine Intelligence and Learning, Causal AI ...', metadata={'title': 'Global Science and Engineering (GSE): Omniscient AI Technology ...', 'source': 'https://www.linkedin.com/pulse/omniscient-technology-machine-ontology-ontological-azamat-abdoullaev'}),\n",
       " Document(page_content='Omniscient definition, having complete or unlimited knowledge, awareness, or understanding; perceiving all things. See more.', metadata={'title': 'Omniscient Definition & Meaning | Dictionary.com', 'source': 'https://www.dictionary.com/browse/omniscient'}),\n",
       " Document(page_content='Omniscien Technologies (formerly Asia Online) is a privately owned company delivering machine translation and language processing software and services. The company is backed by individual investors and institutional venture capital. Omniscien Technologies is headquartered in Singapore, with RD ope', metadata={'title': 'Omniscien Technologies - Alchetron, The Free Social Encyclopedia', 'source': 'https://alchetron.com/Omniscien-Technologies'}),\n",
       " Document(page_content='Tech admin December 20, 2022 011 mins Omniscient neurotechnology is revolutionizing the way we think about our future. This new technology is transforming how we interact with our environment and making it easier to access vast amounts of data. As we move forward, this technology promises to play an increasingly important role in our lives.', metadata={'title': 'The Future Of Mind Reading | Omniscient Neurotechnology - Tech Buzzer', 'source': 'https://www.techbuzzer.org/omniscient-neurotechnology/'}),\n",
       " Document(page_content='Naturally, Omniscien tools and technologies are heavily reliant on high-quality specialized data to power our platform and technologies. Because we understand the importance of high-quality data, the Omniscien team is dedicated to breaking new ground with novel research and approaches to creating, mining, harvesting, synthesizing, and ...', metadata={'title': 'The Omniscien Advantage - We wrote the leading academic machine ...', 'source': 'https://omniscien.com/blog/the-omniscien-advantage-we-wrote-the-book/'}),\n",
       " Document(page_content='About Omniscien Technologies (Trading) is actively using 37 technologies for its website, according to BuiltWith. These include Viewport Meta , IPhone / Mobile Compatible , and Google Font API. Website Tech Stack by BuiltWith Active Technology', metadata={'title': 'Omniscien Technologies (Trading) - Tech Stack, Apps ... - Crunchbase', 'source': 'https://www.crunchbase.com/organization/omniscien-technologies-trading/technology'}),\n",
       " Document(page_content='Company Profile . URGENTLY REQUIRED !!! Asia Online trading as Omniscien Technologies is a market leading artificial intelligence and language technology company that develops and provides ground-breaking automated machine translation and language processing technologies, products and services under the Language Studio™ brand to...', metadata={'title': 'Omniscien Technologies Jobs and Careers, Reviews - Joblum', 'source': 'https://th.joblum.com/company/omniscien-technologies'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    sp_docs = text_splitter.split_documents(documents)\n",
    "    return sp_docs\n",
    "sp_docs = split_docs(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='t. e. Omniscience ( / ɒmˈnɪʃəns /) [1] is the capacity to know everything. In Buddhism, Hinduism, Sikhism and the Abrahamic religions, this is an attribute of God. In Jainism, omniscience is an attribute that any individual can eventually attain. In Buddhism, there are differing beliefs about omniscience among different schools.', metadata={'title': 'Omniscience - Wikipedia', 'source': 'https://en.wikipedia.org/wiki/Omniscience'}),\n",
       " Document(page_content='omniscient: [adjective] having infinite awareness, understanding, and insight.', metadata={'title': 'Omniscient Definition & Meaning - Merriam-Webster', 'source': 'https://www.merriam-webster.com/dictionary/omniscient'}),\n",
       " Document(page_content='Omniscien Technologies Rise of the Machines: Balancing Language-Related AI Opportunities and Risks Securing the Future of Generative AI, Machine Translation, Speech Recognition, NLP and AI Augmented Processes Tuesday 25 April 2023 Watch the Replay', metadata={'title': 'Webinars - Omniscien Technologies', 'source': 'https://omniscien.com/resources/webinars/'}),\n",
       " Document(page_content='The Omniscient Technology enables creating \"the first ultraintelligent machine, the last invention that man need ever make\", as True Real AI or Causal Machine Intelligence and Learning, Causal AI ...', metadata={'title': 'Global Science and Engineering (GSE): Omniscient AI Technology ...', 'source': 'https://www.linkedin.com/pulse/omniscient-technology-machine-ontology-ontological-azamat-abdoullaev'}),\n",
       " Document(page_content='Omniscient definition, having complete or unlimited knowledge, awareness, or understanding; perceiving all things. See more.', metadata={'title': 'Omniscient Definition & Meaning | Dictionary.com', 'source': 'https://www.dictionary.com/browse/omniscient'}),\n",
       " Document(page_content='Omniscien Technologies (formerly Asia Online) is a privately owned company delivering machine translation and language processing software and services. The company is backed by individual investors and institutional venture capital. Omniscien Technologies is headquartered in Singapore, with RD ope', metadata={'title': 'Omniscien Technologies - Alchetron, The Free Social Encyclopedia', 'source': 'https://alchetron.com/Omniscien-Technologies'}),\n",
       " Document(page_content='Tech admin December 20, 2022 011 mins Omniscient neurotechnology is revolutionizing the way we think about our future. This new technology is transforming how we interact with our environment and making it easier to access vast amounts of data. As we move forward, this technology promises to play an increasingly important role in our lives.', metadata={'title': 'The Future Of Mind Reading | Omniscient Neurotechnology - Tech Buzzer', 'source': 'https://www.techbuzzer.org/omniscient-neurotechnology/'}),\n",
       " Document(page_content='Naturally, Omniscien tools and technologies are heavily reliant on high-quality specialized data to power our platform and technologies. Because we understand the importance of high-quality data, the Omniscien team is dedicated to breaking new ground with novel research and approaches to creating, mining, harvesting, synthesizing, and ...', metadata={'title': 'The Omniscien Advantage - We wrote the leading academic machine ...', 'source': 'https://omniscien.com/blog/the-omniscien-advantage-we-wrote-the-book/'}),\n",
       " Document(page_content='About Omniscien Technologies (Trading) is actively using 37 technologies for its website, according to BuiltWith. These include Viewport Meta , IPhone / Mobile Compatible , and Google Font API. Website Tech Stack by BuiltWith Active Technology', metadata={'title': 'Omniscien Technologies (Trading) - Tech Stack, Apps ... - Crunchbase', 'source': 'https://www.crunchbase.com/organization/omniscien-technologies-trading/technology'}),\n",
       " Document(page_content='Company Profile . URGENTLY REQUIRED !!! Asia Online trading as Omniscien Technologies is a market leading artificial intelligence and language technology company that develops and provides ground-breaking automated machine translation and language processing technologies, products and services under the Language Studio™ brand to...', metadata={'title': 'Omniscien Technologies Jobs and Careers, Reviews - Joblum', 'source': 'https://th.joblum.com/company/omniscien-technologies'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "custom_prompt_template = \"\"\" Use the following pieces that data from google search of information to answer the user's question.\n",
    "If you don't know the answer, please just say that you don't know the answer, don't try to make up\n",
    "an answer. \n",
    "\n",
    "Context : {context}\n",
    "Question : {question}\n",
    "\n",
    "Only returns the helpful and reasonable answer below and nothing else.\n",
    "No need to return the question and don't return duplicate answer. Please don't show unhelpful answers.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_prompt():\n",
    "    prompt = PromptTemplate(template=custom_prompt_template, input_variables=['context',\n",
    "                                                                              'question'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    n_gpu_layers = 32  # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    llm = LlamaCpp(\n",
    "        model_path=\"/home/sira/sira_project/meta-Llama2/llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_batch=n_batch,\n",
    "        callback_manager=callback_manager,\n",
    "        verbose=True,n_ctx = 4096, temperature = 0.1, max_tokens = 4096, \n",
    "    )\n",
    "    return llm\n",
    "\n",
    "\n",
    "def load_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"thenlper/gte-base\",\n",
    "                                       model_kwargs = {'device': 'cpu'})\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate(source_list):\n",
    "    res = []\n",
    "    for i in source_list:\n",
    "        if i not in res:\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "def convert_to_website_format(urls):\n",
    "    convert_urls = []\n",
    "    for url in urls:\n",
    "        # Remove any '.html' at the end of the URL\n",
    "        url = re.sub(r'\\.html$', '', url)\n",
    "        # Check if the URL starts with 'www.' or 'http://'\n",
    "        if not re.match(r'(www\\.|http://)', url):\n",
    "            url = 'https://' + url\n",
    "        if '/index' in url:\n",
    "            url = url.split('/index')[0]\n",
    "        match = re.match(r'^([^ ]+)', url)\n",
    "        if match:\n",
    "            url = match.group(1)\n",
    "        convert_urls.append(url)\n",
    "    return convert_urls\n",
    "\n",
    "def regex_source(answer):\n",
    "    pattern = r\"'source': '(.*?)'\"\n",
    "    matchs = re.findall(pattern, str(answer))\n",
    "    convert_urls = convert_to_website_format(matchs)\n",
    "    res_urls = check_duplicate(source_list=convert_urls)\n",
    "    #res_urls = filter_similar_url(res_urls)\n",
    "    return res_urls\n",
    "\n",
    "def filter_similar_url(urls):\n",
    "    urls_remove = [\"www.omniscien.com/aboutus/company\",\"www.omniscien.com/lsev6/asr/automatic-speech-recognition-overview\", \"www.omniscien.com/lsev6/features/asr/autonomous-speech-recognition-overview\",\"www.omniscien.com/lsev6/asr\"]\n",
    "    # Remove the URL from the list\n",
    "    filtered_urls = [url for url in urls if url not in  urls_remove]\n",
    "    return filtered_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_search(db_similarity, diff_val):\n",
    "    filter_list = []\n",
    "    top_score = db_similarity[0][1]\n",
    "    for index, score in enumerate(db_similarity) :\n",
    "        if score[1] - top_score <= diff_val:\n",
    "              filter_list.append(score)\n",
    "    return filter_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/sira/sira_project/meta-Llama2/llama-2-7b-chat.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 7354.73 MB (+ 2048.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 2048.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "#DB_FAISS_PATH = \"/home/sira/sira_project/meta-Llama2/vectorstores_clean_doc_gte-base/db_faiss\"\n",
    "embeddings = load_embeddings()\n",
    "db = FAISS.from_documents(sp_docs, embeddings)\n",
    "llm = load_llm()\n",
    "qa_prompt = set_custom_prompt()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, input_key=\"query\", output_key=\"result\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = db.as_retriever(search_kwargs = {'k':3}), \n",
    "    return_source_documents = True,\n",
    "    memory = memory,\n",
    "    chain_type_kwargs = {\"prompt\":qa_prompt}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the company profile provided, Omniscien Technologies is headquartered in Singapore, and does not provide any information about the Prime Minister of Thailand. Therefore, I cannot provide an answer to this question.According to the company profile provided, Omniscien Technologies is headquartered in Singapore, and does not provide any information about the Prime Minister of Thailand. Therefore, I cannot provide an answer to this question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 88740.76 ms\n",
      "llama_print_timings:      sample time =    28.96 ms /    48 runs   (    0.60 ms per token,  1657.69 tokens per second)\n",
      "llama_print_timings: prompt eval time = 88740.66 ms /   327 tokens (  271.38 ms per token,     3.68 tokens per second)\n",
      "llama_print_timings:        eval time = 16751.25 ms /    47 runs   (  356.41 ms per token,     2.81 tokens per second)\n",
      "llama_print_timings:       total time = 105679.35 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m response \u001b[39m=\u001b[39m qa_chain({\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m: query})\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m urls \u001b[39m=\u001b[39m regex_source(response)\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m count, url \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(urls):\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(count\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, url)\n",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m, in \u001b[0;36mregex_source\u001b[0;34m(answer)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregex_source\u001b[39m(answer):\n\u001b[1;32m     25\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m(.*?)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     matchs \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(pattern, \u001b[39mstr\u001b[39m(answer))\n\u001b[1;32m     27\u001b[0m     convert_urls \u001b[39m=\u001b[39m convert_to_website_format(matchs)\n\u001b[1;32m     28\u001b[0m     res_urls \u001b[39m=\u001b[39m check_duplicate(source_list\u001b[39m=\u001b[39mconvert_urls)\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "query = \"Who is the Prime Minister in Thailand\"\n",
    "start = time.time()\n",
    "#db_similarity = db.similarity_search_with_score(query, k=10)\n",
    "#filter_list = filter_search(db_similarity, diff_val)\n",
    "response = qa_chain({'query': query})\n",
    "print(response[\"result\"])\n",
    "urls = regex_source(response)\n",
    "for count, url in enumerate(urls):\n",
    "    print(str(count+1)+\":\", url)\n",
    "end = time.time()\n",
    "print(\"Respone time:\",int(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-lama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
